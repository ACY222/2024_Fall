# Graph Theory

[TOC]

## Elementary Graph Algorithms

### Representations of Graphs

- Adjacency List
    - Memory Complexity: $O(V + E)$
    - Pros and Cons
        - Provide a compact way to represent sparse graphs
        - Less efficient when we want to determine whether there is an edge
    between u and v
- Adjacency Matrix
    - Memory Complexity: $O(V^2)$
    - Pros and Cons
        - We can simply store the weight of edges as the entry in the matrix.
        For unweighted graph, it needs only one bit per entry
        - More memory required if the graph is sparse

### Breadth First Search

- We can divide the vertices into three groups:
    1. Already visited
    2. Going to be visited right now
    3. To be visited
- Pseudocode
    ```python
    BFS(G, s)
        for each u in G.V - {s} do  # O(V)
            u.d = INFTY
            u.p = NIL
        s.d = 0
        s.p = 0
        Q = {}
        enqueue(Q, s)
        while Q is not empty do
            u = dequeue(Q)
            for each v in G.Adj[u] do   # O(V + E)
                if visited[v] == 0 do
                    v.d = u.d + 1
                    v.p = u
                    enqueue(Q, v)
    ```
- Time complexity: $O(V + E)$
- Breadth-first Trees
    - BST algorithm construct parent-relation trees when searching the graph
    - Pseudocode
        ```python
        PRINT_TREE(G, s, v) # print the tree of path(s, v)
            while(v != NULL) do
                if v != s then
                    push(v)
                    v = v.p
                    continue
                print s
                while stack is not empty do # v == s
                    print pop()
                return
            print "no path from s to v"
            return
        ```

### Depth First Search

- Pseudocode
    ```python
    DFS(G)
        for each vertex u in G.V do
            visited[u] = false
            u.p = NIL
        time = 0
        for each vertex u in G.V do
            if visited[u] == false then
                DFS_VISIT(G, u)
    # construct a tree, consisting of all vertices that are reacheable for u
    DFS_VISIT(G, u, time)       
        time = time + 1
        u.d = time
        visited[u] = true
        for each v in G.Adj[u] do
            if visited[v] == false then
                v.p = u
                DFS_VISIT(G, v, time)
        time = time + 1
        u.f = time
    ```
- Time complexity: $O(V + E)$

### Topological Sort

- DAG: directed acyclic graph
- Topological Sort: a topological sort of a DAG is a linear ordering of all
its vertices such that if G contains an edge $(u, v)$, then u appears before
v in the ordering
- By DFS
    - Pseudocode
        ```python
        TOPOLOGICAL_SORT_DFS(G)
            call DFS(G) to compute finishing times v.f for each v in G.V
            as a vertex is finished, insert it onto the front of a linked list
            return the linked list of vertices
        ```
    - Time complexity: $O(V+E)$
- By BFS
    - Pseudocode
        ```python
        TOPOLOGICAL_SORT_BFS(G)
            use list degree[V] to record all vertices' degree
            enqueue(Q, u) for all vertices u with 0 degree
            while Q is not empty do
                u = dequeue(Q)
                insert u onto the end of a linked list
                for each v in G.Adj[u] do
                    degree[v]--
                    if degree[v] == 0 then
                        enqueue(Q, v)
            return the linked list of vertices
        ```

### Strongly Connected Components(强连通子图)

- A classic application of DFS: decomposing a directed graph into its strongly
connected components
- Pseudocode
    ```python
    Strongly_Connected_Components(G)
        1. call DFS(G) to compute u.f for all vertices u
        2. compute G^T  # reverse the direction of edges
        # in the order of decreasing u.f can ensure that we begin at the roots
        of the trees generated in 1
        3. call DFS(G^T), and in main loop of DFS, consider the vertices in
        order of decreasing u.f(as computed in 1)
        4. output the vertices of each tree in the depth-first forest formed
        in 3 as a separate strongly connected component
    ```


## Minimum Spanning Tree

- Problem Description
    - Given a connected, undirected graph $G = (V, E)$, for each edge in E 
    has a corresponding weight
    - We wish to find an acyclic subset $T \subset E$ that connects all the
    vertices and whose total weight is minimized
    - Obviously, T forms a tree, and we call it Minimum Spanning Tree
- Some definitions
    - Cut: A cut $(S,V-S)$ of an undirected graph G is a partition of V
    - Cross: An edge $(u,v) \in E$ crosses the cut if one of its endpoints
    is in $S$ and the other is in $V-S$
    - Light edge: An edge is a light edge crossing a cut if its weight is
    the minimum of any edge crossing the cut
    - Respect: We call a cut respects a set A of edges if no edge in A crosses
    the cut
    - Safe: If $A$ is a subset of E that is included in some minimum spanning
    tree for G, and $(S,V-S)$ is any cut of G that respects $A$, $(u,v)$ is
    a light edge crossing $(S,V-S)$. Then edge $(u,v)$ is safe for $A$

### Krustal's Algorithm $O(E\log V)$

- The set A forms a forest. The safe edge added to A is always a least-weight
edge in the graph that connects two distinct components
- Pseudocode
    ```python
    MST_KRUSTAL(G, w)
        A = {}
        for each vertex v in G.V do     # O(V)
            MAKE_SET(v)     
        sort the edges of G.E into nondecreasing order by weight w  # O(E logE)
        # O(E)
        for each edge (u, v) in G.E, taking in nondecreasing order by weight do
            if FIND_SET(u) != FIND_SET(v) then
                add (u, v) to A
                UNION(u, v)
        return A
    ```
- Time complexity: $O(E\log E) = O(E\log V)$

### Prim's Algorithm $O(E\log V)$

- The set A froms a single tree. The safe edge added to A is always a
least-weight edge connecting the tree to a vertex not in the tree
- Pseudocode
    ```python
    MST_PRIM(G, w, r)
        for each vertex v in G.V do     # O(V)
            v.key = INFTY
            v.p = NIL
        r.key = 0   # set r as the start node
        Q = G.V     # Q contains nodes not yet joining the tree
        while Q is not empty do         # O(V)
            u = EXTRACT_MIN(Q)          # O(log V), adding (u.p, u) to the tree
            for each vertex v in G.adj[u] do    # O(E) totally, 
                if v in Q and w(u, v) < v.key then      # updating keys
                    v.p = u
                    v.key = w(u, v)     # O(log V), DECREASE_KEY
        return
    ```
- Time complexity: $O(V + V\log V + E\log V) = O(E\log)$

## Single-Source Shortest Paths

- Problem Description: 
    - Given a weighted, directed graph $G = (V, E)$, with weight function 
    $w: E \to \mathbb{R}$ mapping edges to real-valued weights. The weight
    of path $p = <v_0, \ldots, v_k>$ is the sum of the weights of its 
    constituent edges:$$w(p) = \Sigma_{i=1}^k w(v_{i-1}, v_i)$$
    - We define the shortest-path weight $\delta(u,v)$ from u to v by
    $$\delta(u,v) = \begin{cases} min\{w(p):u \stackrel{p}{\rightsquigarrow}
    v\},\quad \text{if there is a path from u to v} \\
    \infty, \quad otherwise\end{cases}$$

### Bellman-Ford Algorithm $O(VE)$

- Lemma: Subpaths of shortest paths are shortest paths
- Relaxation on an edge (u,v)
    ```python
    RELAX(u, v, w)  # O(1), obviously
        if v.d > u.d + w(u, v)  # v.d is the shortest distance from v to s
            v.d = u.d + w(u, v)
            v.p = u             # update the predecessor
    ```
- Path-relaxation property: If $p = <v_0, \ldots, v_k>$ is a shortest path
from $v_0$ to $v_k$, and we relax the edges of p in the order $(v_0, v_1),
\ldots, (v_{k-1}, v_k)$, then $v_k.d = \delta(s, v_k)$
- Bellman-Ford Algorithm
    - `Thought`: For every shortest path, there is $|V| - 1$ edges at most,
    otherwise there will be loops in it. So if we do relaxations to all
    edges for $|V| - 1$ times, you will always find the sequence of edges
    in p. Therefore, the shortest path is found.
    - pesudocode:
        ```python
        BELLMAN-FORD(G, w, s)
            for each v in V do          # O(V)
                v.d = INFTY
                v.p = NIL
            s.d = 0
            for i = 1 to |G.V| - 1      # O(V)
                for each edge (u, v) in G.E # O(E)
                    RELAX(u, v, w)
            # It can test if there are negative loops in the graph
            for each edge (u, v) in G.E
                if v.d > u.d + w(u, v)
                    return FALSE
            return TRUE
        ```
    - Time complexity: O(VE)
    - Pros and cons:
        - Slow: O(VE). But it's efficient when dealing with `DAG`
        (Directed Acyclic Graph) $\to$ Topologically sort the vertices of G,
        and then do relaxation for all edges once.
        - Powerful: It can handle with graphs with negative loops and negative
        edges

### Dijkstra's Algorithm $O(V\log V + E)$

- ***HOW TO DO IT***
- Pesudocode
    ```python
    DIJKSTRA(G, w, s)
        S = {NULL}
        Q = G.V     # |V| 
        while Q is not empty  
            u = EXTRACT_MIN(Q)  # |V| times, log(n) each 
            add u into S
            for v in G.adj[u]   
                RELAX(u, v, w)  # |E| times, O(1) by Fibonacci heap
    ```
- Time complexity: $O(V\log V + E)$
- Pros and cons:
    - Efficient: $O(V\log V + E)$ compared to $O(VE)$
    - Less powerful: It cann't deal with negative edges, let alone negative
    loops

## Multi-Sources Shortest Paths

- In this chapter, we consider the problem of finding shortest paths between
all pairs of vertices in a graph $G(V, E)$

### $O(V^4)$ Time Algorithm

- Optimal Substructure
    - Let $l_{ij}^{(m)}$ be the minimum weight of any path from vertex i to j
    that contains at most m edges. Thus
    $$l_{ij}^{(0)} = \begin{cases} 0,\quad if\; i=j\\
    \infty,\quad if\; i\neq j\end{cases}$$
    For $m\geq 1$, $$l_{ij}^{(m)} = min\{l_{ij}^{(m-1)}, min_{1\leq k\leq n}
    \{l_{ik}^{(m-1)} + w_{kj}\}\} = 
    min_{1\leq k\leq n}\{l_{ik}^{(m-1)}+w_{kj}\}$$
    - Pseudocode
        ```python
        EXTEND_SHORTEST_PATHS(L, w) # from $L^(m-1) to L^(m)$
            n = L.rows  # n = |V|
            let L` be a new n by n matrix
            for i = 1 to n 
                for j = 1 to n 
                    l`[i][j] = INFTY
                    for k = 1 to n
                        l`[i][j] = min(l`[i][j], l[i][k] + w(k, j))
            return L`
        ```
    - Time complexity: $O(V^4)$

### The Floyd-Warshall Algorithm $O(V^3)$

- Assume that there are no negative loops
- Optimal Substructure
    - Let $d_{ij}^{(k)}$ be the weight of a shortest path from vertex i to j
    for which all intermediate vertices are in the set $\{1,2,\ldots, k\}$
    Then $$d_{ij}^{(k)} = \begin{cases} w_{ij},\quad if\; k=0\\
    min\{d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)}\},\quad if\; k \geq 1
    \end{cases}$$
- Pseudocode
    ```python
    FLOYD_WARSHALL(W)
        n = W.rows
        D^0 = W
        for k = 1 to n
            let D^k be a new n by n matrix
            for i = 1 to n 
                for j = 1 to n
                 d^k[i][j] = min(d^(k-1)[i][j], d^(k-1)[i][k] + d^(k-1)[k][j])
        return D^n
    ```
- Time complexity: $O(V^3)$
- Transitive closure of a directed graph
    - Define the transitive closure of G as the graph $G* = (V, E*)$, where
    $(i, j) \in E*$ means there is a path from vertex i to vertex j in G
    - One way to compute the transitive closure of a graph is to assign a
    weight of 1 to each edge of E and run Floyd-Warshall Algorithm, and it
    takes $O(V^3)$. If there is a path from vertex i to j, we get d[i][j] < n,
    otherwise we get d[i][j] = INFTY
    - We can substitue logical OR and logical AND for min and + in 
    Floyd-Warshall Algorithm. By doing it, the time complexity is still 
    $O(V^3)$, but it can save time and space

### Johnson's Algorithm $O(VE + V^2\log V)$

- This algorithm uses the technique of reweighting
- Reweighting
    - To ensure that the weight of each edge is nonnegative, we make a new graph
    $G' = (V', E')$, where $V' = V \cup \{s\}$, for a new vertex $s \notin V$
    and $E' = E \cup \{(s, v), \forall v \in V\}$. And we set $w(s,v) = 0,
    \forall v \in V$
    - ***Define $h(v) = \delta(s,v), \forall v \in V$***. And $$\hat{w}(u,v) =
    w(u,v) + h(u) - h(v)$$ Considering that $\delta(s,v) \leq \delta(s,u) +
    w(u,v)$, namely $h(v) < h(u) + w(u,v)$, we know that 
    $$\hat{w}(u,v) > 0, \forall u, v \in V'$$
- Now there are no negative edges in the graph, we can take Dijkstra's Algorithm
into application in ease
- Pseudocode
    ```python
    JOHNSONO(G, w)
        make a new graph G` mentioned above
        if BELLMAN_FORD(G`, w, s) == FALSE  # O(VE)
            print(The input graph contains negative loops)
        else
            for each vertex v in G`.V
                h(v) = \delta(s, v)     # it was computed by Bellman-Ford
            for each edge (u, v) in G`.E
                \hat{w}(u,v) = w(u, v) + h(u) - h(v)
            let D to be a new n by n matrix
            for each vertex u in G.V    # O(V)
                # O(E + VlogV)
                run DIJKSTRA(G, \hat{w}, u) to compute \hat{\delta}(u,v) for all v in G.V
                # O(V)
                for each vertex v in G.V
                    d[u][v] = \hat{\delta} + h(v) - h(u)
        return D
    ```
- Time complexity: $O(VE + V^2\log V)$
    