# Graph Theory

***Outlines of Topics***
[TOC]

## Outlines

1. Elementary Graph Algorithms
    - BFS: $O(V + E)$
    - DFS: $O(V + E)$
    - Topological Sort: $O(V + E)$
    - SCC: $O(V + E)$
2. Mimimum Spanning Tree
    - Kruskal: $O(E\log V)$
    - Prim: $O((V + E)\log V)$ or $O(V\log V + E)$
3. Single-Source Shortest Paths
    - Bellman-Ford: $O(VE)$
    - Dijkstra: $O(V\log V + E)$
4. Multi-Source Shortest Paths
    - Mundane Dynamic Programming: $O(V^4)$
    - Floyd-Warshall: $O(V^3)$
    - Johnson: $O(VE + V^2\log V)$
5. Maximum Flow
    - Ford-Fulkson Method: $O(E|f^*|)$
    - Edmonds-Karp: $O(VE^2)$
6. Maximum Bipartite Matching
    - $O(VE)$

## Elementary Graph Algorithms

### Representations of Graphs

- Adjacency List
    - Memory Complexity: $O(V + E)$
    - Pros and Cons
        - Provide a compact way to represent sparse graphs
        - Less efficient when we want to determine whether there is an edge
        between u and v, $T = degree(u) + degree(v)$
- Adjacency Matrix
    - Memory Complexity: $O(V^2)$
    - Pros and Cons
        - We can simply store the weight of edges as the entry in the matrix.
        For unweighted graph, it needs only one bit per entry
        - More memory required if the graph is sparse

### Breadth First Search

- We can divide the vertices into three groups:
    1. Already visited
    2. Unvisited
        - prepare to visit right now
        - visit in the future
- Pseudocode
    ```python
    BFS(G, s)
        for each u in G.V - {s} do  # O(V)
            u.d = INFTY
            u.p = NIL
        s.d = 0
        s.p = 0
        Q = {}
        enqueue(Q, s)
        while Q is not empty do         # O(V)
            u = dequeue(Q)
            for each v in G.Adj[u] do   # O(E)
                if visited[v] == 0 do
                    v.d = u.d + 1
                    v.p = u
                    enqueue(Q, v)
    ```
- Time complexity: $O(V + E)$
- Breadth-first Trees
    - BST algorithm construct parent-relation trees when searching the graph
    - Pseudocode
        ```python
        PRINT_TREE(G, s, v) # print the tree of path(s, v)
            while(v != NULL) do
                if v != s then
                    push(v)
                    v = v.p
                    continue
                print s
                while stack is not empty do # v == s
                    print pop()
                return
            print "no path from s to v"
            return
        ```

### Depth First Search

- Pseudocode
    ```python
    DFS(G)
        for each vertex u in G.V do
            visited[u] = false
            u.p = NIL
        time = 0
        for each vertex u in G.V do     # O(V)
            if visited[u] == false then
                DFS_VISIT(G, u)         # O(E)
    # construct a tree, consisting of all vertices that are reacheable for u
    DFS_VISIT(G, u, time)               
        time = time + 1
        u.d = time
        visited[u] = true
        for each v in G.Adj[u] do
            if visited[v] == false then
                v.p = u
                DFS_VISIT(G, v, time)
        time = time + 1
        u.f = time
    ```
- Time complexity: $O(V + E)$

### Topological Sort

- DAG: directed acyclic graph
- Topological Sort: a topological sort of a DAG is a linear ordering of all
its vertices such that if G contains an edge $(u, v)$, then u appears before
v in the ordering
- By DFS
    - Pseudocode
        ```python
        TOPOLOGICAL_SORT_DFS(G)
            call DFS(G) to compute finishing times v.f for each v in G.V
            as a vertex is finished, insert it onto the front of a linked list
            return the linked list of vertices
        ```
    - Time complexity: $O(V+E)$
- By BFS
    - Pseudocode
        ```python
        TOPOLOGICAL_SORT_BFS(G)
            use list degree[V] to record all vertices' degree
            enqueue(Q, u) for all vertices u with 0 degree  // O(V)
            while Q is not empty do
                u = dequeue(Q)
                append u to the linked list
                for each v in G.Adj[u] do
                    degree[v]--
                    if degree[v] == 0 then
                        enqueue(Q, v)
            return the linked list of vertices
        ```
    - Time Complexity: $O(V + E)$

### Strongly Connected Components(强连通子图)

- A classic application of DFS: decomposing a directed graph into its strongly
connected components
- Pseudocode
    ```python
    Strongly_Connected_Components(G)
        # O(V + E)
        1. call DFS(G) to compute the finishing time u.f for all vertices u
        # O(V + E)
        2. compute G^T  # reverse the direction of edges

        # in the order of decreasing u.f can ensure that 
        # we begin at the roots of the trees generated in 1
        # O(V + E)
        3. call DFS(G^T), but in main loop of DFS, consider the vertices in
        order of decreasing u.f(as computed in 1)
        4. output the vertices of each tree in the depth-first forest formed
        in 3 as a separate strongly connected component
    ```
- Time Complexity: $O(V + E)$ (if the graph is represented by adjacent list)

## Minimum Spanning Tree

- Problem Description
    - Given a connected, undirected graph $G = (V, E)$, for each edge in E 
    has a corresponding weight
    - We wish to find an acyclic subset $T \subset E$ that connects all the
    vertices and whose total weight is minimized
    - Obviously, T forms a tree, and we call it Minimum Spanning Tree
- Some definitions
    - Cut: A cut $(S,V-S)$ of an undirected graph G is a partition of V
    - Cross: An edge $(u,v) \in E$ crosses the cut if one of its endpoints
    is in $S$ and the other is in $V-S$
    - Light edge: An edge is a light edge crossing a cut if its weight is
    the minimum of any edge crossing the cut
    - Respect: We call a cut respects a set A of edges if no edge in A crosses
    the cut
    - Safe: If $A$ is a subset of E that is included in some minimum spanning
    tree for G, and $(S,V-S)$ is any cut of G that respects $A$, $(u,v)$ is
    a light edge crossing $(S,V-S)$. Then edge $(u,v)$ is safe for $A$

### Kruskal's Algorithm $O(E\log V)$

- The set A forms a forest. The safe edge added to A is always a least-weight
edge in the graph that connects two distinct components
- Pseudocode
    ```python
    MST_KRUSKAL(G, w)
        A = {}
        for each vertex v in G.V do     # O(V)
            MAKE_SET(v)     
        sort the edges of G.E into nondecreasing order by weight w  # O(E logE)
        # O(E)
        for each edge (u, v) in G.E, taking in nondecreasing order by weight do
            # realized by Disjoint Set Union
            if FIND(u) != FIND(v) then  # O(1)
                add (u, v) to A
                UNION(u, v)             # O(1)
        return A
    ```
- Time complexity: $O(E\log E) = O(E\log V)$

### Prim's Algorithm $O(E\log V)$

- The set A froms a single tree. The safe edge added to A is always a
least-weight edge connecting the tree to a vertex not in the tree
- Pseudocode
    ```python
    MST_PRIM(G, w, r)
        for each vertex v in G.V do     # O(V)
            v.key = INFTY
            v.p = NIL
        r.key = 0   # set r as the start node
        # BUILD-MIN-HEAP, O(V)
        Q = G.V     # Q contains nodes not yet joining the tree
        while Q is not empty do         # O(V)
            # O(log V) for Binary / Binomial / Fibonacci heaps
            u = EXTRACT_MIN(Q)          
            for each vertex v in G.adj[u] do    # O(E) totally, 
                if v in Q and w(u, v) < v.key then      # updating keys
                    v.p = u
                    # use DECREASE_KEY
                    # O(log n) for Binary / Binomial heap, O(1) for Fibonacci heap
                    v.key = w(u, v)     
        return
    ```
- Time complexity:
    - Using Fibonacci Heap: $O(V + V\log V + E) = O(E + V\log V)$
    - Using Others: $O(V + V\log V + E\log V) = O((V + E)\log V)$

## Single-Source Shortest Paths

- Problem Description: 
    - Given a weighted, directed graph $G = (V, E)$, with weight function 
    $w: E \to \mathbb{R}$ mapping edges to real-valued weights. The weight
    of path $p = <v_0, \ldots, v_k>$ is the sum of the weights of its 
    constituent edges:$$w(p) = \Sigma_{i=1}^k w(v_{i-1}, v_i)$$
    - We define the shortest-path weight $\delta(u,v)$ from u to v by
    $$\delta(u,v) = \begin{cases} min\{w(p):u \stackrel{p}{\rightsquigarrow}
    v\},\quad \text{if there is a path from u to v} \\
    \infty, \quad otherwise\end{cases}$$

### Bellman-Ford Algorithm $O(VE)$

- Lemma: Subpaths of shortest paths are shortest paths
- Relaxation on an edge (u,v)
    ```python
    RELAX(u, v, w)  # O(1), obviously
        if v.d > u.d + w(u, v)  # v.d is the shortest distance from v to s
            v.d = u.d + w(u, v)
            v.p = u             # update the predecessor
    ```
- Path-relaxation property: If $p = <v_0, \ldots, v_k>$ is a shortest path
from $v_0$ to $v_k$, and we relax the edges of p in the order $(v_0, v_1),
\ldots, (v_{k-1}, v_k)$, then $v_k.d = \delta(s, v_k)$
- Bellman-Ford Algorithm
    - `Thought`: For every shortest path, there is $|V| - 1$ edges at most,
    otherwise there will be loops in it. So if we do relaxations to all
    edges for $|V| - 1$ times, you will always find the sequence of edges
    in p. Therefore, the shortest path is found.
    - pesudocode:
        ```python
        BELLMAN-FORD(G, w, s)
            for each v in V do          # O(V)
                v.d = INFTY
                v.p = NIL
            s.d = 0
            for i = 1 to |G.V| - 1      # O(V)
                for each edge (u, v) in G.E # O(E)
                    RELAX(u, v, w)
            # It can test if there are negative loops in the graph
            for each edge (u, v) in G.E
                if v.d > u.d + w(u, v)
                # It can be relaxed after V times relaxation, so there must be 
                # negative loops
                    return FALSE
            return TRUE
        ```
    - Time complexity: O(VE)
    - Pros and cons:
        - Slow: O(VE). But it's efficient when dealing with `DAG`
        (Directed Acyclic Graph) $\to$ Topologically sort the vertices of G,
        and then do relaxation for all edges once.
        - Powerful: It can handle with graphs with negative loops and negative
        edges

### Dijkstra's Algorithm $O(V\log V + E)$

- ***HOW TO DO IT***
- Pesudocode
    ```python
    DIJKSTRA(G, w, s)
        S = {NULL}
        Q = G.V     # |V| 
        while Q is not empty  
            u = EXTRACT_MIN(Q)  # |V| times, log(n) each 
            add u into S
            for v in G.adj[u]   
                RELAX(u, v, w)  # |E| times, O(1) by Fibonacci heap
    ```
- Time complexity: $O(V\log V + E)$
- Pros and cons:
    - Efficient: $O(V\log V + E)$ compared to $O(VE)$
    - Less powerful: It cann't deal with negative edges, let alone negative
    loops

## Multi-Sources Shortest Paths

- In this chapter, we consider the problem of finding shortest paths between
all pairs of vertices in a graph $G(V, E)$

### $O(V^4)$ Time Algorithm

- Optimal Substructure
    - Let $l_{ij}^{(m)}$ be the minimum weight of any path from vertex i to j
    that contains at most m edges. Thus
    $$l_{ij}^{(0)} = \begin{cases} 0,\quad if\; i=j\\
    \infty,\quad if\; i\neq j\end{cases}$$
    For $m\geq 1$, $$l_{ij}^{(m)} = min\{l_{ij}^{(m-1)}, min_{1\leq k\leq n}
    \{l_{ik}^{(m-1)} + w_{kj}\}\} = 
    min_{1\leq k\leq n}\{l_{ik}^{(m-1)}+w_{kj}\}$$
- Pseudocode
    ```python
    # repeat this for n times
    EXTEND_SHORTEST_PATHS(L, w) # from $L^(m-1) to L^(m)$
        n = L.rows  # n = |V|
        let L` be a new n by n matrix
        for i = 1 to n              # O(n^3)
            for j = 1 to n 
                l`[i][j] = INFTY
                for k = 1 to n
                    l`[i][j] = min(l`[i][j], l[i][k] + w(k, j))
        return L`
    ```
- Time complexity: $O(V^4)$

### The Floyd-Warshall Algorithm $O(V^3)$

- Assume that there are no negative loops
- Optimal Substructure
    - Let $d_{ij}^{(k)}$ be the weight of a shortest path from vertex i to j
    for which all intermediate vertices are in the set $\{1,2,\ldots, k\}$
    Then $$d_{ij}^{(k)} = \begin{cases} w_{ij},\quad if\; k=0\\
    min\{d_{ij}^{(k-1)}, d_{ik}^{(k-1)} + d_{kj}^{(k-1)}\},\quad if\; k \geq 1
    \end{cases}$$
- Pseudocode
    ```python
    FLOYD_WARSHALL(W)
        n = W.rows  # n = |V|
        D^0 = W
        for k = 1 to n      # O(V)
            let D^k be a new n by n matrix  # O(V^2)
            for i = 1 to n                  # O(V^2)
                for j = 1 to n
                    # with k or without k
                    d^k[i][j] = min(d^(k-1)[i][j], d^(k-1)[i][k] + d^(k-1)[k][j])
        return D^n
    ```
- Time complexity: $O(V^3)$
- Transitive closure of a directed graph
    - Define the transitive closure of G as the graph $G* = (V, E*)$, where
    $(i, j) \in E*$ means there is a path from vertex i to vertex j in G
    - One way to compute the transitive closure of a graph is to assign a
    weight of 1 to each edge of E and run Floyd-Warshall Algorithm, and it
    takes $O(V^3)$. If there is a path from vertex i to j, we get d[i][j] < n,
    otherwise we get d[i][j] = INFTY
    - We can substitue logical OR and logical AND for min and + in 
    Floyd-Warshall Algorithm. By doing it, the time complexity is still 
    $O(V^3)$, but it can save time and space

### Johnson's Algorithm $O(VE + V^2\log V)$

- This algorithm uses the technique of reweighting. It allows us to cope with
    the graphs with negatvie edges but without negative loops
- Reweighting
    - To ensure that the weight of each edge is nonnegative, we make a new graph
    $G' = (V', E')$, where $V' = V \cup \{s\}$, for a new vertex $s \notin V$
    and $E' = E \cup \{(s, v), \forall v \in V\}$. And we set $w(s,v) = 0,
    \forall v \in V$
    - ***Define $h(v) = \delta(s,v), \forall v \in V$***. And $$\hat{w}(u,v) =
    w(u,v) + h(u) - h(v)$$ Considering that $\delta(s,v) \leq \delta(s,u) +
    w(u,v)$, namely $h(v) \leq h(u) + w(u,v)$, we know that 
    $$\hat{w}(u,v) \geq 0, \forall u, v \in V'$$
- Now there are no negative edges in the graph, we can take Dijkstra's Algorithm
into application in ease
- Pseudocode
    ```python
    JOHNSONO(G, w)
        make a new graph G` mentioned above # O(V)
        if BELLMAN_FORD(G`, w, s) == FALSE  # O(VE)
            print(The input graph contains negative loops)
        else
            for each vertex v in G`.V
                h(v) = \delta(s, v)     # it was computed by Bellman-Ford
            for each edge (u, v) in G`.E
                \hat{w}(u,v) = w(u, v) + h(u) - h(v)
            let D to be a new n by n matrix
            for each vertex u in G.V    # O(V)
                # O(E + VlogV)
                run DIJKSTRA(G, \hat{w}, u) to compute \hat{\delta}(u,v) for all v in G.V
                # O(V)
                for each vertex v in G.V
                    d[u][v] = \hat{\delta} + h(v) - h(u)
        return D
    ```
- Time complexity: $O(VE + V^2\log V)$
    
## Maximum Flow

### Flow Networks

- A ***flow network*** $G = (V, E)$ is a directed graph in which each edge has
    a nonnegative capacity $c(u, v) > 0$. And if $(u, v) \in E$, $(v, u) \notin 
    E$. 
- A ***flow*** in a flow network is a function $f: V \times V \rightarrow 
    \mathbb{R}$ that satisfies the following two properties:
    - ***Capacity constraint***: $0 \leq f(u, v) \leq c(u, v)$, for all 
        $(u, v) \in E$
    - ***Flow conservation***: $\sum_{u \in V} f(u, v) = \sum_{u \in V} f(v, u)$,
        for all $v \in V - \{s, t\}$
- The ***value*** of a flow is $\sum_{u \in V} f(s, u) - \sum_{u \in V} f(u, s)$.
    Typically, a flow network will not have any edges into the source, namely
    $\sum_{u \in V} f(u, s) = 0$
- In the ***maximum-flow problem***, we are given a flow network, and we wish
    to find a flow of maximum value
- Some tricks:
    - Antiparallel edges: choose one of the two parallel edges, split it by 
        adding a new vertex and replacing it with two new edges.
        e.g. $(v_1, v_2), (v_2, v_1) \to (v_1, v_2), (v_2, v_3), (v_3, v_1)$
    - Multiple sources and sinks: add a supersource $s$ and a suupersink $t$,
        and connect $s$ to all sources and all sinks to $t$ with edges of infinite
        capacity.

### The Ford-Fulkerson Methond

- The Ford-Fulkerson method is a greedy algorithm that works by repeatedly
        finding `augmenting paths` in `residual networks` and then increasing 
        the flow along those paths. And the algorithm terminates when
        no augmenting path can be found.
- ***Residual Networks***
    - The residual network $G_f$ of a flow $f$ is a flow network with the same
        vertices as $G$ and with edges $(u, v)$ such that $f(u, v) < c(u, v)$
        and $(v, u)$ such that $f(v, u) > 0$.
    - The residual capacity of edges in $G_f$: $c_f(u, v) = c(u, v) - f(u, v)$
        and $c_f(v, u) = f(u, v)$
- ***Augmenting Path***
    - An augmenting path is a simple path from $s$ to $t$ in the residual network
        $G_f$.
    - The ***augmenting flow*** along an augmenting path $P$ is the minimum
        residual capacity of any edge on $P$. Namely, $c_f(p) = min\{c_f(u, v):
        (u, v) \in P\}$.
    - Define a function $f_p: V \times V \to \R$ by 
        $$f_p(u, v) = \begin{cases} c_f(p) & \text{if } (u, v) \in p \\
        0 & \text{otherwise} \end{cases}$$
    - The residual flow $f'$ of a flow $f$ is the flow $f + f_p$.
- ***Max-flow Min-cut Theorem***
    - If $f$ is a flow in a flow network $G$, with source $s$ and sink $t$, then
        the following conditions are equivalent:
        - $f$ is a maximum flow in $G$
        - The residual network $G_f$ contains no augmenting paths
        - $|f| = c(S, T)$ for some $cut(S, T)$ of $G$
- Pesudocode
    ```python
    FORD-FULKERSON(G, s, t)
        for each edge(u, v) in G.E do
            (u, v).f = 0
        while there exists a path p from s to t in the residual network G_f do
            c_f(p) = min{c_f(u, v) : (u, v) in p}
            for each edge(u, v) in p do
                if (u, v) in G.E then
                    (u, v).f = (u, v).f + c_f(p)
                else
                    (v, u).f = (v, u).f - c_f(p)
    ```
- Time complexity: $O(E|f^*|)$
- ***Edmonds-Karp*** algorithms
    - Use BFS to find augmenting paths: choose the shortest path from $s$ to $t$
        in the residual network as the augmenting path.
    - Time complexity: $O(VE^2)$

### Maximum Bipartite Matching

- Construct a flow network in whick flows correspond to matchings
    - Define the corresponding flow network $G' = (V', E')$
    - $V' = V \cup \{s, t\}$, $E' = \{(s, u): u \in L\} \cup \{(u, v): (u, v) \in
        E\} \cup \{(v, t): v \in R\}$
    - Assign unit capacity to each edge in $E'$
- Run the Ford-Fulkson method, and directly obtaining a maximum matching M from
    the integer-valued maximum flow $f$ found
- Time complexity: $O(VE)$

